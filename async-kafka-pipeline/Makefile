.PHONY: help install setup up down logs ps clean init-db run-consumer run-producer test-pipeline health-check

help:
	@echo "ðŸš€ Async Kafka Pipeline - Available Commands:"
	@echo ""
	@echo "ðŸ“¦ Setup & Installation:"
	@echo "  make install      - Install Python dependencies"
	@echo "  make setup        - Complete setup (install + infrastructure + init-db)"
	@echo ""
	@echo "ðŸ—ï¸  Infrastructure:"
	@echo "  make up           - Start all services (Kafka, PostgreSQL, Redis)"
	@echo "  make down         - Stop all services"
	@echo "  make logs         - Show service logs"
	@echo "  make ps           - Show running containers"
	@echo "  make health-check - Check service health"
	@echo ""
	@echo "ðŸ—„ï¸  Database:"
	@echo "  make init-db      - Initialize database tables"
	@echo ""
	@echo "ðŸ”„ Pipeline:"
	@echo "  make run-consumer - Start the Kafka consumer"
	@echo "  make run-producer - Start the event producer (for testing)"
	@echo "  make test-avro    - Test Avro schema and serialization"
	@echo "  make test-avro-integration - Test Avro with Kafka integration"
	@echo "  make test-pipeline - Run complete pipeline test"
	@echo ""
	@echo "ðŸ“Š Monitoring:"
	@echo "  make open-grafana  - Open Grafana dashboard"
	@echo "  make open-prometheus - Open Prometheus"
	@echo "  make metrics       - Show current metrics"
	@echo "  make monitoring-status - Check monitoring stack"
	@echo ""
	@echo "ðŸ§¹ Cleanup:"
	@echo "  make clean        - Clean up everything"
	@echo ""
	@echo "ðŸŒ Web UIs:"
	@echo "  Kafka UI: http://localhost:8080"
	@echo "  Grafana: http://localhost:3000 (admin/admin)"
	@echo "  Prometheus: http://localhost:9090"

# Installation and Setup
install:
	@echo "ðŸ“¦ Installing Python dependencies..."
	poetry install
	@echo "âœ… Dependencies installed!"

setup: install up init-db setup-monitoring
	@echo "ðŸŽ‰ Setup complete! Ready to run the pipeline."

setup-monitoring:
	@echo "ðŸ”§ Setting up monitoring..."
	poetry run python tools/monitoring_setup.py

# Infrastructure Management
up:
	@echo "ðŸ—ï¸  Starting infrastructure services..."
	docker-compose up -d
	@echo "â³ Waiting for services to be healthy..."
	@sleep 15
	@make health-check
	@echo "âœ… Services are running!"
	@echo "ðŸŒ Kafka UI: http://localhost:8080"
	@echo "ðŸŒ Grafana: http://localhost:3000 (admin/admin)"
	@echo "ðŸŒ Prometheus: http://localhost:9090"

down:
	@echo "ðŸ›‘ Stopping all services..."
	docker-compose down

logs:
	docker-compose logs -f

ps:
	docker-compose ps

health-check:
	@echo "ðŸ” Checking service health..."
	poetry run python tools/health_check.py

# Database Operations
init-db:
	@echo "ðŸ—„ï¸  Initializing database..."
	poetry run python scripts/init_db.py
	@echo "âœ… Database initialized!"

# Pipeline Operations
run-consumer:
	@echo "ðŸ”„ Starting Kafka consumer..."
	@echo "Press Ctrl+C to stop"
	poetry run python app/consumer/worker.py

run-producer:
	@echo "ðŸ“¤ Starting event producer..."
	@echo "This will generate test events. Press Ctrl+C to stop"
	poetry run python tools/event_producer.py

# Testing
test-avro:
	@echo "ðŸ§ª Testing Avro schema and serialization..."
	poetry run python tools/test_avro_schema.py

test-avro-integration:
	@echo "ðŸ§ª Testing Avro integration with Kafka..."
	poetry run python tools/test_avro_integration.py

test-pipeline: 
	@echo "ðŸ§ª Running complete pipeline test..."
	@echo "1. Testing Avro schema..."
	@make test-avro
	@echo "2. Checking if services are healthy..."
	@poetry run python tools/health_check.py || (echo "âŒ Services not ready. Run 'make up' first." && exit 1)
	@echo "3. Testing Avro integration..."
	@make test-avro-integration
	@echo "4. Generating test events..."
	poetry run python tools/event_producer.py --count 5 --delay 1
	@echo "5. Check results in database..."
	@make check-db
	@echo "âœ… Pipeline test completed!"

# Development helpers
create-topics:
	@echo "ðŸ“ Creating Kafka topics..."
	docker exec kafka kafka-topics --create --topic orders.raw --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 --if-not-exists
	docker exec kafka kafka-topics --create --topic orders.processed --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 --if-not-exists
	@echo "âœ… Topics created!"

list-topics:
	@echo "ðŸ“‹ Kafka topics:"
	docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

consume-raw:
	@echo "ðŸ‘‚ Listening to raw events (Ctrl+C to stop)..."
	docker exec kafka kafka-console-consumer --topic orders.raw --bootstrap-server localhost:9092 --from-beginning

# Monitoring
monitor-redis:
	@echo "ðŸ“Š Redis monitoring (Ctrl+C to stop)..."
	docker exec -it redis redis-cli monitor

check-db:
	@echo "ðŸ” Database status:"
	docker exec postgres psql -U pipeline_user -d orders_db -c "\dt"
	@echo ""
	@echo "Event count:"
	docker exec postgres psql -U pipeline_user -d orders_db -c "SELECT COUNT(*) as total_events FROM order_events;"
	@echo ""
	@echo "Order states:"
	docker exec postgres psql -U pipeline_user -d orders_db -c "SELECT order_id, status, total_amount FROM order_states LIMIT 5;"

# Monitoring commands
open-grafana:
	@echo "ðŸŒ Opening Grafana dashboard..."
	@echo "URL: http://localhost:3000"
	@echo "Login: admin/admin"

open-prometheus:
	@echo "ðŸŒ Opening Prometheus..."
	@echo "URL: http://localhost:9090"

metrics:
	@echo "ðŸ“Š Application metrics:"
	@curl -s http://localhost:8000/metrics | grep -E "(events_|processing_|fraud_)" || echo "Metrics server not running. Start consumer first."

monitoring-status:
	@echo "ðŸ“Š Monitoring Stack Status:"
	@docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" --filter "name=prometheus" --filter "name=grafana" --filter "name=node-exporter"

# Cleanup
clean:
	@echo "ðŸ§¹ Cleaning up..."
	docker-compose down -v
	docker system prune -f
	rm -rf __pycache__ .pytest_cache .coverage
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -name "*.pyc" -delete 2>/dev/null || true
	@echo "âœ… Cleanup complete!"

# Quick start for new users
quickstart:
	@echo "ðŸš€ Quick Start Guide:"
	@echo ""
	@echo "1. First time setup:"
	@echo "   make setup"
	@echo ""
	@echo "2. Run the pipeline:"
	@echo "   # Terminal 1: Start consumer"
	@echo "   make run-consumer"
	@echo ""
	@echo "   # Terminal 2: Send test events"
	@echo "   make run-producer"
	@echo ""
	@echo "3. Monitor:"
	@echo "   make check-db"
	@echo "   make logs"